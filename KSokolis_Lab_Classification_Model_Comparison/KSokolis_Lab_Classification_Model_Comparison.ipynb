{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4, Lab 1: Predicting Left-Handedness from Psychological Factors\n",
    "> Author: Matt Brems\n",
    "\n",
    "We can sketch out the data science process as follows:\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "We'll walk through a full data science problem in this lab. \n",
    "- However, there are some additional questions along the way that don't fit neatly into the one main example we'll walk through. Any question that isn't explicitly part of the main example is marked with **(detour)** at the start of the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Define The Problem.\n",
    "\n",
    "You're currently a data scientist working at a university. A professor of psychology is attempting to study the relationship between personalities and left-handedness. They have tasked you with gathering evidence so that they may publish.\n",
    "\n",
    "Specifically, the professor says \"I need to prove that left-handedness is caused by some personality trait. Go find that personality trait and the data to back it up.\"\n",
    "\n",
    "As a data scientist, you know that any real data science problem must be **specific** and **conclusively answerable**. For example:\n",
    "- Bad data science problem: \"What is the link between obesity and blood pressure?\"\n",
    "    - This is vague and is not conclusively answerable. That is, two people might look at the conclusion and one may say \"Sure, the problem has been answered!\" and the other may say \"The problem has not yet been answered.\"\n",
    "- Good data science problem: \"Does an association exist between obesity and blood pressure?\"\n",
    "    - This is more specific and is conclusively answerable. The problem specifically is asking for a \"Yes\" or \"No\" answer. Based on that, two independent people should both be able to say either \"Yes, the problem has been answered\" or \"No, the problem has not yet been answered.\"\n",
    "- Excellent data science problem: \"As obesity increases, how does blood pressure change?\"\n",
    "    - This is very specific and is conclusively answerable. The problem specifically seeks to understand the effect of one variable on the other. \n",
    "\n",
    "> You might find it helpful to check out the codebook in the repo for some inspiration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Obtain the data.\n",
    "\n",
    "### 2. Read in the file titled \"data.csv.\"\n",
    "> Hint: Despite being saved as a .csv file, you won't be able to simply `pd.read_csv()` this data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>fromgoogle</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NL</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  ...   country  fromgoogle  engnat  \\\n",
       "0   4   1   5   1   5   1   5   1   4    1  ...        US           2       1   \n",
       "1   1   5   1   4   2   5   5   4   1    5  ...        CA           2       1   \n",
       "2   1   2   1   1   5   4   3   2   1    4  ...        NL           2       2   \n",
       "3   1   4   1   5   1   4   5   4   3    5  ...        US           2       1   \n",
       "4   5   1   5   1   5   1   5   1   3    1  ...        US           2       1   \n",
       "\n",
       "   age  education  gender  orientation  race  religion  hand  \n",
       "0   22          3       1            1     3         2     3  \n",
       "1   14          1       2            2     6         1     1  \n",
       "2   30          4       1            1     1         1     2  \n",
       "3   18          2       2            5     3         2     2  \n",
       "4   22          3       1            1     3         2     3  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('../datasets/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Suppose that, instead of us giving you this data in a file, you were actually conducting a survey to gather this data yourself. From an ethics/privacy point of view, what are three things you might consider when attempting to gather this data?\n",
    "> When working with sensitive data like sexual orientation or gender identity, we need to consider how this data could be used if it fell into the wrong hands!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***Do we actually need the data?***\n",
    "># ***Can collection of the data be optional?***\n",
    "># ***Maybe give and option of \"Prefer not to answer\"***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### 4. Conduct exploratory data analysis on this dataset.\n",
    "> If you haven't already, be sure to check out the codebook in the repo, as that will help in your EDA process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4184, 56)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q1</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>1.962715</td>\n",
       "      <td>1.360291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.829589</td>\n",
       "      <td>1.551683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.846558</td>\n",
       "      <td>1.664804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.186902</td>\n",
       "      <td>1.476879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.865440</td>\n",
       "      <td>1.545798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q6</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.672084</td>\n",
       "      <td>1.342238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q7</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.216539</td>\n",
       "      <td>1.490733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q8</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.184512</td>\n",
       "      <td>1.387382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.761233</td>\n",
       "      <td>1.511805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q10</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.522945</td>\n",
       "      <td>1.242890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q11</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.748805</td>\n",
       "      <td>1.443078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q12</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.852772</td>\n",
       "      <td>1.556284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q13</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.657505</td>\n",
       "      <td>1.559575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q14</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.334130</td>\n",
       "      <td>1.522866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q15</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.168021</td>\n",
       "      <td>1.501683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q16</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.930210</td>\n",
       "      <td>1.575544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q17</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.564771</td>\n",
       "      <td>1.619010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q18</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.424952</td>\n",
       "      <td>1.413236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q19</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.928537</td>\n",
       "      <td>1.493122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q20</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.639818</td>\n",
       "      <td>1.414569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q21</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.867591</td>\n",
       "      <td>1.360858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q22</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.595124</td>\n",
       "      <td>1.354475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q23</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.861138</td>\n",
       "      <td>1.291425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q24</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.337237</td>\n",
       "      <td>1.426095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q25</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>1.999761</td>\n",
       "      <td>1.290747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q26</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.001434</td>\n",
       "      <td>1.480610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q27</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.730641</td>\n",
       "      <td>1.485883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q28</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.624044</td>\n",
       "      <td>1.481709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q29</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.543738</td>\n",
       "      <td>1.611428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q30</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.894359</td>\n",
       "      <td>1.477968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q31</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.002151</td>\n",
       "      <td>1.420032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q32</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.869503</td>\n",
       "      <td>1.659141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q33</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.741874</td>\n",
       "      <td>1.405670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q34</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.022228</td>\n",
       "      <td>1.562694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q35</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.074092</td>\n",
       "      <td>1.546400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q36</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.610660</td>\n",
       "      <td>1.409707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q37</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.465344</td>\n",
       "      <td>1.521460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q38</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.798757</td>\n",
       "      <td>1.413584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q39</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.569312</td>\n",
       "      <td>1.621772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q40</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.984226</td>\n",
       "      <td>1.483752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q41</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>3.385277</td>\n",
       "      <td>1.423055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q42</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.704828</td>\n",
       "      <td>1.544345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q43</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.676386</td>\n",
       "      <td>1.523097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q44</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.736616</td>\n",
       "      <td>1.471845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>introelapse</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>347.808556</td>\n",
       "      <td>5908.901681</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>252063.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testelapse</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>479.994503</td>\n",
       "      <td>3142.178542</td>\n",
       "      <td>7.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>324.25</td>\n",
       "      <td>119834.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fromgoogle</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>1.576243</td>\n",
       "      <td>0.494212</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engnat</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>1.239962</td>\n",
       "      <td>0.440882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>30.370698</td>\n",
       "      <td>367.201726</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.00</td>\n",
       "      <td>23763.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.317878</td>\n",
       "      <td>0.874264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>1.654398</td>\n",
       "      <td>0.640915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orientation</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>1.833413</td>\n",
       "      <td>1.303454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>5.013623</td>\n",
       "      <td>1.970996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>religion</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>2.394359</td>\n",
       "      <td>2.184164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand</th>\n",
       "      <td>4184.0</td>\n",
       "      <td>1.190966</td>\n",
       "      <td>0.495357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count        mean          std   min    25%    50%     75%  \\\n",
       "Q1           4184.0    1.962715     1.360291   0.0    1.0    1.0    3.00   \n",
       "Q2           4184.0    3.829589     1.551683   0.0    3.0    5.0    5.00   \n",
       "Q3           4184.0    2.846558     1.664804   0.0    1.0    3.0    5.00   \n",
       "Q4           4184.0    3.186902     1.476879   0.0    2.0    3.0    5.00   \n",
       "Q5           4184.0    2.865440     1.545798   0.0    1.0    3.0    4.00   \n",
       "Q6           4184.0    3.672084     1.342238   0.0    3.0    4.0    5.00   \n",
       "Q7           4184.0    3.216539     1.490733   0.0    2.0    3.0    5.00   \n",
       "Q8           4184.0    3.184512     1.387382   0.0    2.0    3.0    4.00   \n",
       "Q9           4184.0    2.761233     1.511805   0.0    1.0    3.0    4.00   \n",
       "Q10          4184.0    3.522945     1.242890   0.0    3.0    4.0    5.00   \n",
       "Q11          4184.0    2.748805     1.443078   0.0    1.0    3.0    4.00   \n",
       "Q12          4184.0    2.852772     1.556284   0.0    1.0    3.0    4.00   \n",
       "Q13          4184.0    2.657505     1.559575   0.0    1.0    3.0    4.00   \n",
       "Q14          4184.0    3.334130     1.522866   0.0    2.0    4.0    5.00   \n",
       "Q15          4184.0    3.168021     1.501683   0.0    2.0    3.0    5.00   \n",
       "Q16          4184.0    2.930210     1.575544   0.0    1.0    3.0    4.00   \n",
       "Q17          4184.0    2.564771     1.619010   0.0    1.0    2.0    4.00   \n",
       "Q18          4184.0    3.424952     1.413236   0.0    2.0    4.0    5.00   \n",
       "Q19          4184.0    2.928537     1.493122   0.0    2.0    3.0    4.00   \n",
       "Q20          4184.0    3.639818     1.414569   0.0    3.0    4.0    5.00   \n",
       "Q21          4184.0    2.867591     1.360858   0.0    2.0    3.0    4.00   \n",
       "Q22          4184.0    3.595124     1.354475   0.0    3.0    4.0    5.00   \n",
       "Q23          4184.0    3.861138     1.291425   0.0    3.0    4.0    5.00   \n",
       "Q24          4184.0    3.337237     1.426095   0.0    2.0    3.0    5.00   \n",
       "Q25          4184.0    1.999761     1.290747   0.0    1.0    1.0    3.00   \n",
       "Q26          4184.0    3.001434     1.480610   0.0    2.0    3.0    4.00   \n",
       "Q27          4184.0    2.730641     1.485883   0.0    1.0    3.0    4.00   \n",
       "Q28          4184.0    2.624044     1.481709   0.0    1.0    3.0    4.00   \n",
       "Q29          4184.0    2.543738     1.611428   0.0    1.0    2.0    4.00   \n",
       "Q30          4184.0    2.894359     1.477968   0.0    1.0    3.0    4.00   \n",
       "Q31          4184.0    3.002151     1.420032   0.0    2.0    3.0    4.00   \n",
       "Q32          4184.0    2.869503     1.659141   0.0    1.0    3.0    5.00   \n",
       "Q33          4184.0    2.741874     1.405670   0.0    1.0    3.0    4.00   \n",
       "Q34          4184.0    3.022228     1.562694   0.0    1.0    3.0    4.00   \n",
       "Q35          4184.0    3.074092     1.546400   0.0    1.0    3.0    5.00   \n",
       "Q36          4184.0    2.610660     1.409707   0.0    1.0    2.0    4.00   \n",
       "Q37          4184.0    3.465344     1.521460   0.0    2.0    4.0    5.00   \n",
       "Q38          4184.0    2.798757     1.413584   0.0    1.0    3.0    4.00   \n",
       "Q39          4184.0    2.569312     1.621772   0.0    1.0    2.0    4.00   \n",
       "Q40          4184.0    2.984226     1.483752   0.0    2.0    3.0    4.00   \n",
       "Q41          4184.0    3.385277     1.423055   0.0    2.0    4.0    5.00   \n",
       "Q42          4184.0    2.704828     1.544345   0.0    1.0    3.0    4.00   \n",
       "Q43          4184.0    2.676386     1.523097   0.0    1.0    3.0    4.00   \n",
       "Q44          4184.0    2.736616     1.471845   0.0    1.0    3.0    4.00   \n",
       "introelapse  4184.0  347.808556  5908.901681   1.0    6.0   12.0   35.00   \n",
       "testelapse   4184.0  479.994503  3142.178542   7.0  186.0  242.0  324.25   \n",
       "fromgoogle   4184.0    1.576243     0.494212   1.0    1.0    2.0    2.00   \n",
       "engnat       4184.0    1.239962     0.440882   0.0    1.0    1.0    1.00   \n",
       "age          4184.0   30.370698   367.201726  13.0   18.0   21.0   27.00   \n",
       "education    4184.0    2.317878     0.874264   0.0    2.0    2.0    3.00   \n",
       "gender       4184.0    1.654398     0.640915   0.0    1.0    2.0    2.00   \n",
       "orientation  4184.0    1.833413     1.303454   0.0    1.0    1.0    2.00   \n",
       "race         4184.0    5.013623     1.970996   0.0    5.0    6.0    6.00   \n",
       "religion     4184.0    2.394359     2.184164   0.0    1.0    2.0    2.00   \n",
       "hand         4184.0    1.190966     0.495357   0.0    1.0    1.0    1.00   \n",
       "\n",
       "                  max  \n",
       "Q1                5.0  \n",
       "Q2                5.0  \n",
       "Q3                5.0  \n",
       "Q4                5.0  \n",
       "Q5                5.0  \n",
       "Q6                5.0  \n",
       "Q7                5.0  \n",
       "Q8                5.0  \n",
       "Q9                5.0  \n",
       "Q10               5.0  \n",
       "Q11               5.0  \n",
       "Q12               5.0  \n",
       "Q13               5.0  \n",
       "Q14               5.0  \n",
       "Q15               5.0  \n",
       "Q16               5.0  \n",
       "Q17               5.0  \n",
       "Q18               5.0  \n",
       "Q19               5.0  \n",
       "Q20               5.0  \n",
       "Q21               5.0  \n",
       "Q22               5.0  \n",
       "Q23               5.0  \n",
       "Q24               5.0  \n",
       "Q25               5.0  \n",
       "Q26               5.0  \n",
       "Q27               5.0  \n",
       "Q28               5.0  \n",
       "Q29               5.0  \n",
       "Q30               5.0  \n",
       "Q31               5.0  \n",
       "Q32               5.0  \n",
       "Q33               5.0  \n",
       "Q34               5.0  \n",
       "Q35               5.0  \n",
       "Q36               5.0  \n",
       "Q37               5.0  \n",
       "Q38               5.0  \n",
       "Q39               5.0  \n",
       "Q40               5.0  \n",
       "Q41               5.0  \n",
       "Q42               5.0  \n",
       "Q43               5.0  \n",
       "Q44               5.0  \n",
       "introelapse  252063.0  \n",
       "testelapse   119834.0  \n",
       "fromgoogle        2.0  \n",
       "engnat            2.0  \n",
       "age           23763.0  \n",
       "education         4.0  \n",
       "gender            3.0  \n",
       "orientation       5.0  \n",
       "race              7.0  \n",
       "religion          7.0  \n",
       "hand              3.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Model the data.\n",
    "\n",
    "### 5. Suppose I wanted to use Q1 - Q44 to predict whether or not the person is left-handed. Would this be a classification or regression problem? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***Classification. The output is discrete.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (detour) 6. While this isn't the problem we set out to solve, suppose I wanted to predict the exact age of the respondent using Q1 - Q44 as my predictors. Would this be a classification or regression problem? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***Regression. Age is continuous.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. We want to use $k$-nearest neighbors to predict whether or not a person is left-handed based on their responses to Q1 - Q44. Before doing that, however, you remember that it is often a good idea to standardize your variables. In general, why would we standardize our variables? Give an example of when we would standardize our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***We standardize our variables to put everything on the same scale.***\n",
    "\n",
    "># ***If we tried to pridict income of a household based strictly on number of kids and lot size, the coefficiant of number of kids would be large compared to the coefficiant of lot size.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Give an example of when we might not standardize our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:*** \n",
    "># ***Similarly scaled variables.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Based on your answers to 7 and 8, do you think we should standardize our predictor variables in this case? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***No, scales are similar.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. We want to use $k$-nearest neighbors to predict whether or not a person is left-handed. What munging/cleaning do we need to do to our $y$ variable in order to explicitly answer this question? Do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3542\n",
       "2     452\n",
       "3     179\n",
       "0      11\n",
       "Name: hand, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3732\n",
       "1     452\n",
       "Name: 0=right,1=left, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['0=right,1=left'] = [1 if i == 2 else 0 for i in df['hand']]\n",
    "df['0=right,1=left'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['hand'] != 0].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. The professor for whom you work suggests that you set $k = 4$. Why might this be a bad idea in this specific case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***Even numbers can lead to misleading results. Ties and such.***\n",
    "># ***Best to use odd. 3 or 5 is recommended.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Let's *(finally)* use $k$-nearest neighbors to predict whether or not a person is left-handed!\n",
    "\n",
    "> Be sure to create a train/test split with your data!\n",
    "\n",
    "> Create four separate models, one with $k = 3$, one with $k = 5$, one with $k = 15$, and one with $k = 25$.\n",
    "\n",
    "> Instantiate and fit your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['index', 'introelapse', 'testelapse', 'country',\n",
    "       'fromgoogle', 'engnat', 'age', 'education', 'gender', 'orientation',\n",
    "       'race', 'religion', 'hand', '0=right,1=left'], axis = 1)\n",
    "\n",
    "y = df['0=right,1=left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_3 = KNeighborsClassifier(n_neighbors = 3)\n",
    "k_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_5 = KNeighborsClassifier(n_neighbors = 5)\n",
    "k_5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_15 = KNeighborsClassifier(n_neighbors = 15)\n",
    "k_15.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=25, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_25 = KNeighborsClassifier(n_neighbors = 25)\n",
    "k_25.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being good data scientists, we know that we might not run just one type of model. We might run many different models and see which is best.\n",
    "\n",
    "### 13. We want to use logistic regression to predict whether or not a person is left-handed. Before we do that, let's check the [documentation for logistic regression in sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Is there default regularization? If so, what is it? If not, how do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***C : float, default: 1.0***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. We want to use logistic regression to predict whether or not a person is left-handed. Before we do that, should we standardize our features? Well, the answer is (as always), **it depends**. What is one reason you would standardize? What is one reason you would not standardize?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***An example of when I would standardize in logistic regression is when I also wanted to regularize.***\n",
    "># ***An example of when I would not standardize in logistic regression is when scales are already similar.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Let's use logistic regression to predict whether or not the person is left-handed.\n",
    "\n",
    "\n",
    "> Be sure to use the same train/test split with your data as with your $k$-NN model above!\n",
    "\n",
    "> Create four separate models, one with LASSO and $\\alpha = 1$, one with LASSO and $\\alpha = 10$, one with Ridge and $\\alpha = 1$, and one with Ridge and $\\alpha = 10$. *(Hint: Be careful with how you specify $\\alpha$ in your model!)*\n",
    "\n",
    "> Instantiate and fit your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_1 = LogisticRegression(penalty = 'l1', C = 0.1)\n",
    "lasso_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_10 = LogisticRegression(penalty = 'l1', C = 1.0)\n",
    "lasso_10.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_1 = LogisticRegression(penalty = 'l2', C = 0.1)\n",
    "ridge_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_10 = LogisticRegression(penalty = 'l2', C = 1.0)\n",
    "ridge_10.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Evaluate the model(s).\n",
    "\n",
    "### 16. Before calculating any score on your data, take a step back. Think about your $X$ variable and your $Y$ variable. Do you think your $X$ variables will do a good job of predicting your $Y$ variable? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***No. What do psych factors have to do with hand dominance?*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Using accuracy as your metric, evaluate all eight of your models on both the training and testing sets. Put your scores below. (If you want to be fancy and generate a table in Markdown, there's a [Markdown table generator site linked here](https://www.tablesgenerator.com/markdown_tables#).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy k = 3 0.9156279961649089\n",
      "testing accuracy k = 3 0.8496168582375478\n",
      "training accuracy k = 5 0.8996484499840205\n",
      "testing accuracy k = 5 0.8735632183908046\n",
      "training accuracy k = 15 0.8951741770533717\n",
      "testing accuracy k = 15 0.8812260536398467\n",
      "training accuracy k = 25 0.8951741770533717\n",
      "testing accuracy k = 25 0.8812260536398467\n",
      "logreg training accuracy lasso a = 1 0.8954937679769894\n",
      "logreg testing accuracy lasso a = 1 0.8812260536398467\n",
      "logreg training accuracy lasso a = 10 0.8954937679769894\n",
      "logreg testing accuracy lasso a = 10 0.8812260536398467\n",
      "logreg training accuracy ridge a = 1 0.8954937679769894\n",
      "logreg testing accuracy ridge a = 1 0.8812260536398467\n",
      "logreg training accuracy ridge a = 10 0.8951741770533717\n",
      "logreg testing accuracy ridge a = 10 0.8812260536398467\n"
     ]
    }
   ],
   "source": [
    "print('training accuracy k = 3 ' + str(k_3.score(X_train, y_train)))\n",
    "print('testing accuracy k = 3 ' + str(k_3.score(X_test, y_test)))\n",
    "\n",
    "print('training accuracy k = 5 ' + str(k_5.score(X_train, y_train)))\n",
    "print('testing accuracy k = 5 ' + str(k_5.score(X_test, y_test)))\n",
    "\n",
    "print('training accuracy k = 15 ' + str(k_15.score(X_train, y_train)))\n",
    "print('testing accuracy k = 15 ' + str(k_15.score(X_test, y_test)))\n",
    "\n",
    "print('training accuracy k = 25 ' + str(k_25.score(X_train, y_train)))\n",
    "print('testing accuracy k = 25 ' + str(k_25.score(X_test, y_test)))\n",
    "\n",
    "print('logreg training accuracy lasso a = 1 ' + str(lasso_1.score(X_train, y_train)))\n",
    "print('logreg testing accuracy lasso a = 1 ' + str(lasso_1.score(X_test, y_test)))\n",
    "\n",
    "print('logreg training accuracy lasso a = 10 ' + str(lasso_10.score(X_train, y_train)))\n",
    "print('logreg testing accuracy lasso a = 10 ' + str(lasso_10.score(X_test, y_test)))\n",
    "\n",
    "print('logreg training accuracy ridge a = 1 ' + str(ridge_1.score(X_train, y_train)))\n",
    "print('logreg testing accuracy ridge a = 1 ' + str(ridge_1.score(X_test, y_test)))\n",
    "\n",
    "print('logreg training accuracy ridge a = 10 ' + str(ridge_10.score(X_train, y_train)))\n",
    "print('logreg testing accuracy ridge a = 10 ' + str(ridge_10.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| training | output | testing | output|\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|training accuracy k = 3 | 0.9156279961649089|testing accuracy k = 3 | 0.8496168582375478|\n",
    "|training accuracy k = 5 | 0.8996484499840205|testing accuracy k = 5 | 0.8735632183908046|\n",
    "|training accuracy k = 15 | 0.8951741770533717|testing accuracy k = 15 | 0.8812260536398467|\n",
    "|training accuracy k = 25 | 0.8951741770533717|testing accuracy k = 25 | 0.8812260536398467|\n",
    "|logreg training accuracy lasso a = 1 | 0.8954937679769894|logreg testing accuracy lasso a = 1 | 0.8812260536398467|\n",
    "|logreg training accuracy lasso a = 10 | 0.8954937679769894|logreg testing accuracy lasso a = 10 | 0.8812260536398467|\n",
    "|logreg training accuracy ridge a = 1 | 0.8954937679769894|logreg testing accuracy ridge a = 1 | 0.8812260536398467|\n",
    "|logreg training accuracy ridge a = 10 | 0.8951741770533717|logreg testing accuracy ridge a = 10 | 0.8812260536398467|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. In which of your $k$-NN models is there evidence of overfitting? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***k = 3 and k = 5***\n",
    "># ***The trainings score better than the testing.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Broadly speaking, how does the value of $k$ in $k$-NN affect the bias-variance tradeoff? (i.e. As $k$ increases, how are bias and variance affected?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***As k decreases, our bias decreases and our variance increases.***\n",
    "># ***As k increases, our bias increases and our variance decreases.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. If you have a $k$-NN model that has evidence of overfitting, what are three things you might try to do to combat overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***- Reduce predictors***\n",
    "># ***- Increase k***\n",
    "># ***- Try logreg***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. In which of your logistic regression models is there evidence of overfitting? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***None.*** \n",
    "># ***All of the testing scores are better than the training scores.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. Broadly speaking, how does the value of $C$ in logistic regression affect the bias-variance tradeoff? (i.e. As $C$ increases, how are bias and variance affected?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***As C goes down our variance decreases and our bias increases.***\n",
    "># ***As C goes up our variance increase and our bias decreases.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. For your logistic regression models, play around with the regularization hyperparameter, $C$. As you vary $C$, what happens to the fit and coefficients in the model? What might this mean in the context of this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***Nothing seems to change as C changes.***\n",
    "># ***Likely need better X variables.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24. If you have a logistic regression model that has evidence of overfitting, what are three things you might try to do to combat overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***Get more data.***\n",
    "># ***Remove some features.***\n",
    "># ***Try lasso.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Answer the problem.\n",
    "\n",
    "### 25. Suppose you want to understand which psychological features are most important in determining left-handedness. Would you rather use $k$-NN or logistic regression? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***Logreg do to estimating coefs.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. Select a logistic regression model. Interpret the coefficient for `Q1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01978977, -0.04362395, -0.04693673, -0.06088196,  0.10951742,\n",
       "         0.02875591, -0.00321948, -0.14268086, -0.04024473,  0.06593426,\n",
       "        -0.02369211,  0.        , -0.04471947,  0.00456571, -0.00972691,\n",
       "         0.01272543,  0.04393458, -0.01434006, -0.04057943, -0.05023702,\n",
       "        -0.02359995, -0.05404905, -0.02922946, -0.01236549,  0.06027034,\n",
       "         0.07572057, -0.02629942,  0.02626792,  0.02470894,  0.00690672,\n",
       "         0.04863997, -0.01209977, -0.04623348,  0.01756564,  0.02339307,\n",
       "        -0.06290626, -0.03631335,  0.09053533, -0.07633563, -0.09311776,\n",
       "        -0.05866217, -0.06455702, -0.08424839, -0.01491415]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_10.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Coef Q1 = -0.0198***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. If you have to select one model overall to be your *best* model, which model would you select? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># ***Answer:***\n",
    "># ***Logreg do to estimating coefs.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28. BONUS: \n",
    "### Circle back to the three specific and conclusively answerable questions you came up with in Q1. Answer these for the professor based on the model you selected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS:\n",
    "Looking for more to do? Probably not - you're busy! But if you want to, consider exploring the following:\n",
    "- Suppose this data were in a `SQL` database named `data` and a table named `inventory`. What `SQL` query would return the count of people who were right-handed, left-handed, both, or missing with their class labels of 1, 2, 3, and 0, respectively? (You can assume you've already logged into the database.)\n",
    "- Fit and evaluate one or more of the generalized linear models discussed above.\n",
    "- Create a plot comparing training and test metrics for various values of $k$ and various regularization schemes in logistic regression.\n",
    "- Rather than just evaluating models based on accuracy, consider using sensitivity, specificity, etc.\n",
    "- In the context of predicting left-handedness, why are unbalanced classes concerning? If you were to re-do this process given those concerns, what changes might you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
